<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<title>Web Audio Viz - Start</title>
	<style>
		body {
		background: #eeeeee;
		font-family: tahoma, verdana, sans serif;
	}

	canvas {
		margin-left:10px;
		margin-top:10px;
		box-shadow: 4px 4px 8px rgba(0,0,0,0.5);
		background: black;
	}

	#controls{
		margin-left:10px;
		margin-top:10px;
  }
  
  section{
  	margin-bottom:1em;
  }
  
  #playButton{
  	font-size: 1.2em;
  	width: 3.5em;
  }
  
	button[data-playing="yes"]:after{
		content: "Pause";
	}
	
	button[data-playing="no"]:after{
		content: "Play";
	}
	
	#fsButton{
  	font-size: 1.2em;
  	width: 6em;
  }
	</style>
	<script>
		"use strict";

		window.onload = init;

		// SCRIPT SCOPED VARIABLES

		// 1- here we are faking an enumeration - we'll look at another way to do this soon 
		const SOUND_PATH = Object.freeze({
			sound1: "media/New Adventure Theme.mp3",
			sound2: "media/Peanuts Theme.mp3",
			sound3: "media/The Picard Song.mp3"
		});

		// 2 - elements on the page
		let audioElement, canvasElement;

		let invert = false, tintRed = false, noise = false, sepia = false;
		let brightness = 0;

		// UI
		let playButton;

		// 3 - our canvas drawing context
		let drawCtx

		// 4 - our WebAudio context
		let audioCtx;

		// 5 - nodes that are part of our WebAudio audio routing graph
		let sourceNode, analyserNode, gainNode;

		// 6 - a typed array to hold the audio frequency data
		const NUM_SAMPLES = 256;
		// create a new array of 8-bit integers (0-255)
		let audioData = new Uint8Array(NUM_SAMPLES / 2);

		let maxRadius;

		let delayAmount = 0.5;
		let delayNode;


		// FUNCTIONS
		function init() {
			setupWebaudio();
			setupCanvas();
			setupUI();
			update();
		}

		function setupWebaudio() {
			// 1 - The || is because WebAudio has not been standardized across browsers yet
			const AudioContext = window.AudioContext || window.webkitAudioContext;
			audioCtx = new AudioContext();

			// 2 - get a reference to the <audio> element on the page
			audioElement = document.querySelector("audio");
			audioElement.src = SOUND_PATH.sound3;

			// 3 - create an a source node that points at the <audio> element
			sourceNode = audioCtx.createMediaElementSource(audioElement);

			// 4 - create an analyser node
			analyserNode = audioCtx.createAnalyser();

			delayNode = audioCtx.createDelay();
			delayNode.delayTime.value = delayAmount;

			/*
			We will request NUM_SAMPLES number of samples or "bins" spaced equally 
			across the sound spectrum.
			
			If NUM_SAMPLES (fftSize) is 256, then the first bin is 0 Hz, the second is 172 Hz, 
			the third is 344Hz. Each bin contains a number between 0-255 representing 
			the amplitude of that frequency.
			*/

			// fft stands for Fast Fourier Transform
			analyserNode.fftSize = NUM_SAMPLES;

			// 5 - create a gain (volume) node
			gainNode = audioCtx.createGain();
			gainNode.gain.value = 1;

			sourceNode.connect(audioCtx.destination);

			sourceNode.connect(delayNode);
			delayNode.connect(analyserNode);
			analyserNode.connect(audioCtx.destination);
		}

		function setupCanvas() {
			canvasElement = document.querySelector('canvas');
			drawCtx = canvasElement.getContext("2d");
		}

		function setupUI() {
			playButton = document.querySelector("#playButton");
			playButton.onclick = e => {
				console.log(`audioCtx.state = ${audioCtx.state}`);

				// check if context is in suspended state (autoplay policy)
				if (audioCtx.state == "suspended") {
					audioCtx.resume();
				}

				if (e.target.dataset.playing == "no") {
					audioElement.play();
					e.target.dataset.playing = "yes";
					// if track is playing pause it
				} else if (e.target.dataset.playing == "yes") {
					audioElement.pause();
					e.target.dataset.playing = "no";
				}

			};

			let volumeSlider = document.querySelector("#volumeSlider");
			volumeSlider.oninput = e => {
				gainNode.gain.value = e.target.value;
				volumeLabel.innerHTML = Math.round((e.target.value / 2 * 100));
			};
			volumeSlider.dispatchEvent(new InputEvent("input"));

			let radiusSlider = document.querySelector("#radiusSlider");
			let radiusLabel = document.querySelector("#radiusLabel");
			radiusSlider.oninput = e => {
				maxRadius = parseInt(e.target.value);
				radiusLabel.textContent = e.target.value;
			};
			radiusSlider.dispatchEvent(new InputEvent("input"));


			document.querySelector("#trackSelect").onchange = e => {
				audioElement.src = e.target.value;
				// pause the current track if it is playing
				playButton.dispatchEvent(new MouseEvent("click"));
			};


			// if track ends
			audioElement.onended = _ => {
				playButton.dataset.playing = "no";
			};

			document.querySelector("#fsButton").onclick = _ => {
				requestFullscreen(canvasElement);
			};

			// Checkboxes
			document.querySelector("input[value='tint-red']").onchange = e => {tintRed = e.target.checked;};
			document.querySelector("input[value='invert']").onchange = e => {invert = e.target.checked;};
			document.querySelector("input[value='noise']").onchange = e => {noise = e.target.checked;};
			document.querySelector("input[value='sepia']").onchange = e => {sepia = e.target.checked;};

			// Brightness
			let brightnessLabel = document.querySelector("#brightnessLabel");
			let brightnessSlider = document.querySelector("#brightnessSlider");
			brightnessSlider.oninput = e => {
				brightness = parseInt(e.target.value);
				brightnessLabel.textContent = e.target.value;
			};
			brightnessSlider.dispatchEvent(new InputEvent("input"));

			// Delay
			let delayLabel = document.querySelector("#delayLabel");
			let delaySlider = document.querySelector("#delaySlider");
			delaySlider.oninput = e => {
				delayAmount = parseFloat(e.target.value);
				delayNode.delayTime.value = delayAmount;
				delayLabel.textContent = e.target.value;
			};
			delaySlider.dispatchEvent(new InputEvent("input"));

		}

		function update() {
			// this schedules a call to the update() method in 1/60 seconds
			requestAnimationFrame(update);

			/*
				Nyquist Theorem
				http://whatis.techtarget.com/definition/Nyquist-Theorem
				The array of data we get back is 1/2 the size of the sample rate 
			*/

			// populate the audioData with the frequency data
			// notice these arrays are passed "by reference" 
			analyserNode.getByteFrequencyData(audioData);

			// OR
			//analyserNode.getByteTimeDomainData(audioData); // waveform data

			// DRAW!
			drawCtx.clearRect(0, 0, 800, 600);
			let barWidth = 4;
			let barSpacing = 1;
			let barHeight = 100;
			let topSpacing = 50;

			// loop through the data and draw!
			for (let i = 0; i < audioData.length; i++) {

				/*
				drawCtx.fillStyle = 'rgba(0,255,0,0.6)';

				// the higher the amplitude of the sample (bin) the taller the bar
				// remember we have to draw our bars left-to-right and top-down
				drawCtx.fillRect(i * (barWidth + barSpacing), topSpacing + 256 - audioData[i], barWidth, barHeight);

				drawCtx.fillStyle = "rgba(255,0,0,0.6)";
				drawCtx.fillRect(640 - i * (barWidth + barSpacing), topSpacing + 256 - audioData[i] - 20, barWidth, barHeight);
				*/

				let percent = audioData[i] / 255;
				let circleRadius = percent * maxRadius;

				// red-ish circles
				drawCtx.beginPath();
				drawCtx.fillStyle = makeColor(255, 111, 111, .34 - percent / 3.0);
				drawCtx.arc(canvasElement.width / 2, canvasElement.height / 2, circleRadius, 0, 2 * Math.PI, false);
				drawCtx.fill();
				drawCtx.closePath();

				// blue-ish circles
				drawCtx.beginPath();
				drawCtx.fillStyle = makeColor(0, 0, 255, .10 - percent / 10.0);
				drawCtx.arc(canvasElement.width / 2, canvasElement.height / 2, circleRadius * 1.5, 0, 2 * Math.PI, false);
				drawCtx.fill();
				drawCtx.closePath();

				// yellow-ish circles
				drawCtx.beginPath();
				drawCtx.fillStyle = makeColor(200, 200, 0, .5 - percent / 5.0);
				drawCtx.arc(canvasElement.width / 2, canvasElement.height / 2, circleRadius * .5, 0, 2 * Math.PI, false);
				drawCtx.fill();
				drawCtx.closePath();
			}

			drawCtx.beginPath();
			drawCtx.moveTo(0,0);
			let baseline = canvasElement.height * .95;
			drawCtx.strokeStyle = "white";
			for (let i = 0; i < audioData.length; i++){
				let xPercent = i / audioData.length;
				let yPercent = audioData[i] / 255;
				let y = baseline - (yPercent * baseline);
				drawCtx.lineTo(xPercent * canvasElement.width, y);
			}
			drawCtx.stroke();
			drawCtx.closePath();

			manipulatePixels(drawCtx);

		}



		// HELPER FUNCTIONS
		function makeColor(red, green, blue, alpha) {
			var color = 'rgba(' + red + ',' + green + ',' + blue + ', ' + alpha + ')';
			return color;
		}

		function requestFullscreen(element) {
			if (element.requestFullscreen) {
				element.requestFullscreen();
			} else if (element.mozRequestFullscreen) {
				element.mozRequestFullscreen();
			} else if (element.mozRequestFullScreen) { // camel-cased 'S' was changed to 's' in spec
				element.mozRequestFullScreen();
			} else if (element.webkitRequestFullscreen) {
				element.webkitRequestFullscreen();
			}
			// .. and do nothing if the method is not supported
		};

		function manipulatePixels(ctx) {
			let imageData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height);
			let data = imageData.data;
			let length = data.length;
			let width = data.width;

			let i;
			for (i = 0; i < length; i += 4) {
				if (tintRed) {
					data[i] = data[i] + 100;
				}
				if (invert) {
					let red = data[i], green = data[i+1], blue = data[i+2];
					data[i] = 255 - red;
					data[i+1] = 255 - green;
					data[i+2] = 255 - blue;
				}
				if (noise && Math.random() < .10) {
					data[i] = data[i+1] = data[i+2] = 128;
					data[i+3] = 255; // alpha
				}
				if (sepia) {
					let red = data[i], green = data[i+1], blue = data[i+2];					
					data[i] = (red * .393) + (green * .769) + (blue * .189);
					data[i+1] = (red * .349) + (green * .686) + (blue * .168);
					data[i+2] = (red * .272) + (green * .534) + (blue * .131);
				}
				// Brightness
				data[i] += brightness;
				data[i+1] += brightness;
				data[i+2] += brightness;
			}
			ctx.putImageData(imageData, 0, 0);
		}
	</script>
</head>

<body>
	<canvas width="640" height="400"></canvas>
	<div id="controls">
		<audio></audio>
		<section>
			<label>Track:
				<select id="trackSelect">
					<option value="media/New Adventure Theme.mp3">New Adventure Theme</option>
					<option value="media/Peanuts Theme.mp3">Peanuts Theme</option>
					<option value="media/The Picard Song.mp3" selected>The Picard Song</option>
				</select>
			</label>
			<button id="playButton" data-playing="no"></button>
			<button id="fsButton">Full Screen</button>
		</section>
		<section>
			Volume: <input type="range" id="volumeSlider" min="0" max="2" value="1" step="0.01">
			<span id="volumeLabel">???</span>
		</section>
		<section>
			Circle Radius: <input type="range" id="radiusSlider" min="0" max="400" value="200" step="1">
			<span id="radiusLabel">???</span>
		</section>
		<section>
			Tint Red<input type="checkbox" value="tint-red">
			Invert<input type="checkbox" value="invert">
			Noise<input type="checkbox" value="noise">
			Sepia<input type="checkbox" value="sepia">
		</section>
		<section>
			Brightness: <input type="range" id="brightnessSlider" min="-128" max="128">
			<span id="brightnessLabel">???</span>
		</section>
		<section>
			Delay: <input type="range" id="delaySlider" min="0.0" max="1.0" step="0.01">
			<span id="delayLabel">???</span>
		</section>
	</div>

</body>

</html>